{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Explainer\n",
    "\n",
    "Here we visualize the explainer results and analyze specific graph theoretic properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = '../log/'\n",
    "# Here all the required .npy files are directly under log\n",
    "expdir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enron_base_h20_o20',\n",
       " 'grad',\n",
       " 'graph',\n",
       " 'mask',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_400graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_405graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_410graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_415graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_420graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_425graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_430graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_435graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_440graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_445graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_450graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_455graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_460graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_465graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_470graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_475graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_480graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_485graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_490graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_495graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_500graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_505graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_510graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_515graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_520graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_525graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_530graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_535graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_540graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_545graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_550graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_555graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_560graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_565graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_570graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_575graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_580graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_585graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_590graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_595graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_600graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_605graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_610graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_615graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_620graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_625graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_630graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_635graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_640graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_645graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_650graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_655graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_660graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_665graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_670graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_675graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_680graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_685graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_690graph_idx_-1.npy',\n",
       " 'masked_adj_syn2_base_h20_o20_explainnode_idx_695graph_idx_-1.npy',\n",
       " 'pr',\n",
       " 'syn1_base_h20_o20',\n",
       " 'syn1_base_h20_o20_explain',\n",
       " 'syn2_base_h20_o20',\n",
       " 'syn2_base_h20_o20_explain',\n",
       " 'Tox21_AHR_base_h20_o20',\n",
       " 'Tox21_AHR_base_h20_o20_explain']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load produced masks\n",
    "dirs = os.listdir(os.path.join(logdir, expdir))\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = []\n",
    "\n",
    "# This would print all the files and directories\n",
    "for file in dirs:\n",
    "    # Check if file extension is \".npy\" which are\n",
    "    # numpy binary files to represent large data\n",
    "    if file.split('.')[-1] == 'npy':\n",
    "        # print(file)\n",
    "        masks.append(file)\n",
    "type(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_adjacency_full(mask, ax=None):\n",
    "    \"\"\"Plot full adjacency matrix of the mask\n",
    "\n",
    "    Args:\n",
    "        mask (str): Filename containing the adjacency matrix of the mask\n",
    "        ax (Axes class object, optional): Axis. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        numpy matrix: Full adjacency matrix of the mask\n",
    "    \"\"\"\n",
    "    # Obtain adjacency matrix from the filename sent in var \"mask\"\n",
    "    adj = np.load(os.path.join(logdir, expdir, mask), allow_pickle=True)\n",
    "    # if ax is None:\n",
    "    #     plt.figure()\n",
    "    #     plt.imshow(adj);\n",
    "    # else:\n",
    "    #     ax.imshow(adj)\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_adj(adj,threshold=0.8):\n",
    "    \"\"\"Filter out the values in adjacency matrix that are greater than threshold. Fix the others as 0\n",
    "\n",
    "    Args:\n",
    "        adj (numpy matrix): Adjacency matrix of mask that we have to filter\n",
    "        threshold (float): Filter value\n",
    "\n",
    "    Returns:\n",
    "        numpy matrix: Filtered adjacency matrix\n",
    "    \"\"\"\n",
    "    filt_adj = adj.copy()\n",
    "    filt_adj[adj<threshold] = 0\n",
    "    return filt_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for m in masks: \n",
    "#     fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "#     plt.title(str(m))\n",
    "    \n",
    "#     # Full adjacency\n",
    "#     ax1.set_title('Full Adjacency mask')\n",
    "#     adj = show_adjacency_full(m, ax=ax1)\n",
    "    \n",
    "#     # Filtered adjacency\n",
    "#     f = filter_adj(adj)\n",
    "#     ax2.set_title('Filtered Adjacency mask')\n",
    "#     ax2.imshow(f)\n",
    "    \n",
    "#     # Plot subgraph\n",
    "#     ax3.set_title(\"Subgraph\")\n",
    "#     G = nx.from_numpy_array(f)\n",
    "#     G.remove_nodes_from(list(nx.isolates(G)))\n",
    "#     nx.draw(G, ax=ax3)\n",
    "# print(type(ax1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Graph theoretic properties of each mask\n",
    "\n",
    "Here we measure the following quantities:\n",
    "- Nodes: |V|\n",
    "- Edges: |E|\n",
    "- Avg degree\n",
    "- Diameter of the graph\n",
    "- Sparsity measure: edge density = |E|/C(|V|,2)\n",
    "- Node centrality measure: Betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_symmetric(a, rtol=1e-05, atol=1e-08):\n",
    "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\n",
    "\n",
    "def normalize(A):\n",
    "    scale_factor = A.max() - A.min()\n",
    "    B = np.ones_like(A)*A.min()\n",
    "\n",
    "    A = (A - B)/scale_factor\n",
    "    return A\n",
    "\n",
    "def centrality(adj):\n",
    "    # Get the unweighted adjacency matrix\n",
    "    adj1 = adj.copy()\n",
    "    adj1[adj>0] = 1\n",
    "\n",
    "    # Get the unweighted graph\n",
    "    unweighted_G = nx.from_numpy_matrix(np.matrix(adj1))\n",
    "\n",
    "    # For now we use edge-path centrality later check\n",
    "    # Information centrality metric\n",
    "    ebc = nx.edge_betweenness_centrality(unweighted_G)\n",
    "\n",
    "    # Create a symmetric matrix A with A[i][j] is the betweeness score of edge (i,j)\n",
    "    A = np.zeros_like(adj1)\n",
    "    v = unweighted_G.number_of_nodes()\n",
    "    for i in range(v):\n",
    "        for j in range(i):\n",
    "            if (j,i) in ebc.keys():\n",
    "                # The keys in ebc are (a,b) with a < b\n",
    "                A[i][j] = A[j][i] = ebc[(j,i)]\n",
    "    \n",
    "    # Now that we have got A, we see if the importance given by GNNExplainer\n",
    "    # has some relation with the centrality scores in A\n",
    "    A1 = normalize(A)\n",
    "    B1 = normalize(adj)\n",
    "    # For coherence check the following two links:\n",
    "    # 1) https://www.geeksforgeeks.org/cosine-similarity-calculation-between-two-matrices-in-matlab/\n",
    "    # 2) https://math.stackexchange.com/questions/507742/distance-similarity-between-two-matrices#:~:text=If%20we%20have%20two%20matrices,squares%20of%20all%20singular%20values.\n",
    "    coherence = 1/(np.linalg.norm(A1 - B1,2))**2\n",
    "\n",
    "    return coherence\n",
    "\n",
    "def graph_prop(adj):\n",
    "    # Edge weighted graph\n",
    "    weighted_G = nx.from_numpy_matrix(np.matrix(adj))\n",
    "\n",
    "    v = weighted_G.number_of_nodes()\n",
    "    e = weighted_G.number_of_edges()\n",
    "    avg_degree = float('%.3f'%(2*e/v))\n",
    "    diameter = nx.diameter(weighted_G)\n",
    "    sparsity = float('%.3f'%(2*e/(v*(v-1))))\n",
    "    coherence = float('%.3f'%(centrality(adj)))\n",
    "\n",
    "    return [v,e,avg_degree,diameter,sparsity,coherence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for m in masks:\n",
    "    # Full adjacency matrix\n",
    "    adj = show_adjacency_full(m)\n",
    "    # Get the metrics of each mask\n",
    "    data.append(graph_prop(adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>Size</th>\n",
       "      <th>Average Degree</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Sparsity</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>153.483333</td>\n",
       "      <td>479.216667</td>\n",
       "      <td>6.062067</td>\n",
       "      <td>5.916667</td>\n",
       "      <td>0.042633</td>\n",
       "      <td>0.412300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52.644472</td>\n",
       "      <td>219.189268</td>\n",
       "      <td>0.841364</td>\n",
       "      <td>0.278718</td>\n",
       "      <td>0.009872</td>\n",
       "      <td>0.121684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>4.673000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>113.000000</td>\n",
       "      <td>314.750000</td>\n",
       "      <td>5.407250</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.035750</td>\n",
       "      <td>0.302250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>147.500000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>5.998000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.421000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>165.250000</td>\n",
       "      <td>571.000000</td>\n",
       "      <td>6.813000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>0.510250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>337.000000</td>\n",
       "      <td>1321.000000</td>\n",
       "      <td>7.840000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.649000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Order         Size  Average Degree   Diameter   Sparsity  \\\n",
       "count   60.000000    60.000000       60.000000  60.000000  60.000000   \n",
       "mean   153.483333   479.216667        6.062067   5.916667   0.042633   \n",
       "std     52.644472   219.189268        0.841364   0.278718   0.009872   \n",
       "min     84.000000   217.000000        4.673000   5.000000   0.023000   \n",
       "25%    113.000000   314.750000        5.407250   6.000000   0.035750   \n",
       "50%    147.500000   446.000000        5.998000   6.000000   0.042000   \n",
       "75%    165.250000   571.000000        6.813000   6.000000   0.050250   \n",
       "max    337.000000  1321.000000        7.840000   6.000000   0.064000   \n",
       "\n",
       "       Coherence  \n",
       "count  60.000000  \n",
       "mean    0.412300  \n",
       "std     0.121684  \n",
       "min     0.205000  \n",
       "25%     0.302250  \n",
       "50%     0.421000  \n",
       "75%     0.510250  \n",
       "max     0.649000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the above data into a data frame\n",
    "df = pd.DataFrame(data, columns=[\"Order\",\"Size\",\"Average Degree\",\"Diameter\",\"Sparsity\",\"Coherence\"])\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
